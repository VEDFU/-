{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "import gc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib as  mpl\n",
    "from matplotlib  import pyplot as plt\n",
    "mpl.rcParams[u'font.sans-serif'] = ['simhei']\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "from datetime import timedelta\n",
    "from datetime import datetime\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.获取历史数据\n",
    "针对特定场景数据做相应的处理，不具备通用性  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m   5368\u001b[0m                      \u001b[0mright_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mright_on\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mleft_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5369\u001b[0m                      \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mright_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5370\u001b[0;31m                      copy=copy, indicator=indicator, validate=validate)\n\u001b[0m\u001b[1;32m   5371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5372\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecimals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     55\u001b[0m                          \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mright_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                          \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindicator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m                          validate=validate)\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0;31m# to avoid incompat dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_coerce_merge_keys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# If argument passed to validate,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_maybe_coerce_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    928\u001b[0m                 \u001b[0mtyp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlk_is_cat\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m                 self.left = self.left.assign(\n\u001b[0;32m--> 930\u001b[0;31m                     **{name: self.left[name].astype(typ)})\n\u001b[0m\u001b[1;32m    931\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0mtyp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrk_is_cat\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   2692\u001b[0m         \u001b[0;31m# ... and then assign\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2693\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2694\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2695\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2518\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2519\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2521\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2584\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2585\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2586\u001b[0;31m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2588\u001b[0m         \u001b[0;31m# check if we are modifying a copy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   1952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1953\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1954\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1955\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1956\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mset\u001b[0;34m(self, item, value, check)\u001b[0m\n\u001b[1;32m   3996\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3997\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blklocs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3998\u001b[0;31m                     \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblk_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3999\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blklocs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mdelete\u001b[0;34m(self, loc)\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mDelete\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mplace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \"\"\"\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mdelete\u001b[0;34m(arr, obj, axis)\u001b[0m\n\u001b[1;32m   4898\u001b[0m         \u001b[0mkeep\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4899\u001b[0m         \u001b[0mslobj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4900\u001b[0;31m         \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mslobj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4901\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4902\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 1. 读取数据\n",
    "dataset = pd.read_csv('./train/dataset.csv', index_col=0)\n",
    "dbd_faultcode = pd.read_csv('./train/dbd_faultcode.csv', encoding='GBK' )\n",
    "train_data = dataset.merge(dbd_faultcode,how = 'left',on = [\"SPN\",\"FMI\"])\n",
    "up_data = train_data\n",
    "up_data.COLLECTTIME = pd.to_datetime(up_data.COLLECTTIME)\n",
    "up_data.sort_values(by='COLLECTTIME', inplace=True)\n",
    "# 删除明显异常的行\n",
    "drop_rows = [0, 1, 2, 3]\n",
    "drop_rows.extend([x for x in range(1875076, 1875088)])\n",
    "up_data.drop(drop_rows, axis=0, inplace=True)\n",
    "# 默认填充为0\n",
    "up_data[\"FLAG\"] = 0\n",
    "# 筛选出故障编码不为空的UNIQUENO(一个UNIQUENO可假设为一台机器)\n",
    "prob_uniqs = up_data[up_data.CODE.notnull()].UNIQUENO.unique()\n",
    "\n",
    "# 2.出现故障的时间段进行标记\n",
    "'''\n",
    "minutes = 300\n",
    "'''\n",
    "# 设定优先级，对于少数种类的故障，优先标记\n",
    "code_prev = {\n",
    "    1206: 0,\n",
    "    1141: 1,\n",
    "    1182: 2,\n",
    "    1168: -1,\n",
    "    1239: -1,\n",
    "    1168: -1,\n",
    "    1211: -1,\n",
    "    1216: -1,\n",
    "    1209: -1,\n",
    "    1145: -1,\n",
    "    1341: -1,\n",
    "    1246: -1,\n",
    "    1215: -1,\n",
    "    1122: -1\n",
    "}\n",
    "\n",
    "delta = timedelta(minutes = 300)\n",
    "left_delta = delta\n",
    "right_delta = delta\n",
    "# 从有故障的设备列表中取出一台设备\n",
    "for dev_id in prob_uniqs:\n",
    "    # 取出这台设备的全部数据\n",
    "    cdf = up_data[up_data.UNIQUENO == dev_id].copy()\n",
    "    cdf['index'] = cdf.index\n",
    "    cdf.reset_index(inplace=True)\n",
    "    # 取出这台设备故障码不为空的数据\n",
    "    notna_cdf = cdf[cdf.CODE.notna()]\n",
    "#     print(datetime.now(), dev_id, cdf.shape[0], notna_cdf.shape[0])\n",
    "    cdf_len = cdf.shape[0]\n",
    "    # 在这台设备数据中遍历不为空的位置\n",
    "    for i in notna_cdf.index:\n",
    "        dt = cdf.at[i, 'COLLECTTIME']\n",
    "        code = cdf.at[i, 'CODE']\n",
    "        # 在前后时间间隔内打标签\n",
    "        for y in range(i, -1, -1):\n",
    "            y_code = up_data.at[cdf.at[y, 'index'], 'FLAG']\n",
    "            if y_code > 0 and code_prev[y_code] >= code_prev[code]:\n",
    "                break\n",
    "            elif cdf.at[y, 'COLLECTTIME'] >= dt - left_delta:\n",
    "                up_data.at[cdf.at[y, 'index'], 'FLAG'] = code\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        for y in range(i + 1, cdf_len, 1):\n",
    "            y_code = up_data.at[cdf.at[y, 'index'], 'FLAG']\n",
    "            if y_code > 0 and code_prev[y_code] >= code_prev[code]:\n",
    "                break\n",
    "            elif cdf.at[y, 'COLLECTTIME'] <= dt + right_delta:\n",
    "                up_data.at[cdf.at[y, 'index'], 'FLAG'] = code\n",
    "            else:\n",
    "                break\n",
    "\n",
    "# 3.保留有用的列\n",
    "#columns_filter,util_cols由人工提供\n",
    "columns_filter = ['CD_VP_UNIQUENO', 'AREA', 'ROAD', 'LONGITUDE', 'LATITUDE', 'SPEED',\n",
    "       'DIRECTION', 'ALTITUDE', 'ACCSTATE', 'POWERDOWNSTATE', 'LOCATIONSTATE',\n",
    "       'WORKHOURS', 'ACCRUNTIMES', 'ACCWORKTIMES', 'PRESSURE',\n",
    "       'WATERTEMPERATURE', 'OILLOCATION', 'OILTEMPERATURE', 'OILPRESSURE',\n",
    "       'ROUNDSPEED', 'ACCEXCCOUNT', 'GSMSIGNAL', 'WORKDETAILID',\n",
    "       'VEHICLESTATUS', 'TERMINALSTATUS', 'SATELLITE', 'TERMINALEL_OUTSIDE',\n",
    "       'TERMINALEL_INSIDE', 'INSIDE_TEMPERATURE', 'INSIDE_HUMIDITY',\n",
    "       'MILENUMBER', 'OILVALUE1', 'OILVALUE2', 'MIXSTATE', 'QUSHOILTIMES',\n",
    "       'ENVTEMPERATURE', 'PULSESIGNS', 'ENVHUMIDITY', 'OILPERCENT1',\n",
    "       'ELCANDVOL', 'WIRELESSTEMP1', 'WIRELESSTEMP2', 'WIRELESSTEMP3',\n",
    "       'WIRELESSTEMP4', 'SIMNO', 'OPTOILLEVEL', 'ENGINELOADSTATE', 'CMDTYPE',\n",
    "       'ISANALYSED', 'VERSIONNUM', 'LOCK_INSTRUMENT', 'ALARM_0010',\n",
    "       'ALARM_0003', 'ALARM_0008', 'ALARM_0005', 'ALARM_0006', 'ALARM_0007',\n",
    "       'ALARM_0009', 'LOWVOLTAGESTATUS', 'ALARM_0002', 'ALARM_0004',\n",
    "       'ALARM_0001', 'THROTTLECURRENT', 'CURRENTSPEEDLOADPERCENTAGE',\n",
    "       'ENGINETORQUEPERCENT', 'ROTATIONALSPEED', 'ENGINERUNTIMES',\n",
    "       'COOLANTTEMPERATURE', 'ENGINEOILTEMPERATURE', 'INTAKETEMPERATURE',\n",
    "       'TEMPERATURE', 'LUBRICATINGOILPRESSURE', 'COOLANTLEVEL',\n",
    "       'INTAKEMANIFOLDTEMPERATURE', 'FUELUSETOTAL', 'OILCONSUMPTIONRATE',\n",
    "       'CURRENTFAULTCOUNT1', 'CURRENTFAULTCOUNT2', 'CURRENTFAULTCOUNT3',\n",
    "       'CURRENTFAULTCOUNT4', 'CURRENTFAULTCOUNT5', 'CURRENTFAULTCOUNT6','FLAG','UNIQUENO','COLLECTTIME']\n",
    "util_cols = ['COLLECTTIME','FLAG','UNIQUENO']\n",
    "\n",
    "# 筛选出这四类故障的数据\n",
    "x_train = up_data[up_data.FLAG.isin({0,1206,1141,1182})]\n",
    "x_data = x_train[columns_filter]\n",
    "y_train = x_data['FLAG']\n",
    "y_train.replace(1206,1,inplace=True)\n",
    "y_train.replace(1141,2,inplace=True)\n",
    "y_train.replace(1182,3,inplace=True)\n",
    "x_data['FLAG'] = y_train.values \n",
    "x_data.index = pd.to_datetime(x_data['COLLECTTIME'])\n",
    "\n",
    "train_x_cols = ['UNIQUENO','CD_VP_UNIQUENO', 'AREA', 'ROAD', 'LONGITUDE', 'LATITUDE', 'SPEED',\n",
    "       'DIRECTION', 'ALTITUDE', 'ACCSTATE', 'POWERDOWNSTATE', 'LOCATIONSTATE',\n",
    "       'WORKHOURS', 'ACCRUNTIMES', 'ACCWORKTIMES', 'PRESSURE',\n",
    "       'WATERTEMPERATURE', 'OILLOCATION', 'OILTEMPERATURE', 'OILPRESSURE',\n",
    "       'ROUNDSPEED', 'ACCEXCCOUNT', 'GSMSIGNAL', 'WORKDETAILID',\n",
    "       'VEHICLESTATUS', 'TERMINALSTATUS', 'SATELLITE', 'TERMINALEL_OUTSIDE',\n",
    "       'TERMINALEL_INSIDE', 'INSIDE_TEMPERATURE', 'INSIDE_HUMIDITY',\n",
    "       'MILENUMBER', 'OILVALUE1', 'OILVALUE2', 'MIXSTATE', 'QUSHOILTIMES',\n",
    "       'ENVTEMPERATURE', 'PULSESIGNS', 'ENVHUMIDITY', 'OILPERCENT1',\n",
    "       'ELCANDVOL', 'WIRELESSTEMP1', 'WIRELESSTEMP2', 'WIRELESSTEMP3',\n",
    "       'WIRELESSTEMP4', 'SIMNO', 'OPTOILLEVEL', 'ENGINELOADSTATE', 'CMDTYPE',\n",
    "       'ISANALYSED', 'VERSIONNUM', 'LOCK_INSTRUMENT', 'ALARM_0010',\n",
    "       'ALARM_0003', 'ALARM_0008', 'ALARM_0005', 'ALARM_0006', 'ALARM_0007',\n",
    "       'ALARM_0009', 'LOWVOLTAGESTATUS', 'ALARM_0002', 'ALARM_0004',\n",
    "       'ALARM_0001', 'THROTTLECURRENT', 'CURRENTSPEEDLOADPERCENTAGE',\n",
    "       'ENGINETORQUEPERCENT', 'ROTATIONALSPEED', 'ENGINERUNTIMES',\n",
    "       'COOLANTTEMPERATURE', 'ENGINEOILTEMPERATURE', 'INTAKETEMPERATURE',\n",
    "       'TEMPERATURE', 'LUBRICATINGOILPRESSURE', 'COOLANTLEVEL',\n",
    "       'INTAKEMANIFOLDTEMPERATURE', 'FUELUSETOTAL', 'OILCONSUMPTIONRATE',\n",
    "       'CURRENTFAULTCOUNT1', 'CURRENTFAULTCOUNT2', 'CURRENTFAULTCOUNT3',\n",
    "       'CURRENTFAULTCOUNT4', 'CURRENTFAULTCOUNT5', 'CURRENTFAULTCOUNT6']\n",
    "train_y_col = ['UNIQUENO','FLAG']\n",
    "his_x = x_data[train_x_cols]\n",
    "his_y = x_data[train_y_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "his_x,his_y为历史数据，用于接下来的模型训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'his_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-ed51bb8766e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhis_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhis_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhis_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhis_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain_ax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_ay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhis_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhis_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'2017-01-01'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'2018-12-12'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# 1.数据预处理\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'his_x' is not defined"
     ]
    }
   ],
   "source": [
    "# 0.自定义历史数据的时间范围\n",
    "start = '2017-01-01'\n",
    "end = '2018-12-12'\n",
    "def get_train(his_x,his_y,start=start, end=end):\n",
    "    return his_x[start:end],his_y[start:end]\n",
    "train_ax, train_ay = get_train(his_x,his_y,start='2017-01-01', end='2018-12-12')\n",
    "\n",
    "# 1.数据预处理\n",
    "# <1>删除dup_col\n",
    "train_x = train_ax.drop(columns=['UNIQUENO']).copy()\n",
    "train_y = train_ay.drop(columns=['UNIQUENO']).copy()\n",
    "null_filter = [col for col in train_x.columns if not train_x[col].isnull().all()] \n",
    "train_x = train_x[null_filter] # 不含UNIQUENO\n",
    "train_UNIQUENO = train_ax[['UNIQUENO']] \n",
    "                  \n",
    "# <2>缺失值处理\n",
    "train_x.fillna(0,inplace=True)\n",
    "train_xy = pd.concat([train_x,train_y], axis=1)\n",
    "# <3>取FLAG=0的数据，即健康数据\n",
    "train_x_baseline = train_xy[train_xy.FLAG==0].drop(columns=['FLAG'])\n",
    "train_x_degraded = train_xy[train_xy.FLAG!=0].drop(columns=['FLAG'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.计算几种metrics\n",
    "# <1>fisher metric\n",
    "cols = train_x_baseline.columns\n",
    "m1 = train_x_baseline.mean().values\n",
    "m2 = train_x_degraded.mean().values\n",
    "var1 = train_x_baseline.var().values\n",
    "var2 = train_x_degraded.var().values\n",
    "a = (m1-m2)*(m1-m2)\n",
    "b1 = var1\n",
    "b2 = var2\n",
    "b = b1+b2\n",
    "fisher_score = a/b\n",
    "fisher_rank = pd.Series(data=fisher_score,index=cols).rank(na_option='drop',ascending=False).sort_values() # rank()不会改变顺序\n",
    "\n",
    "# <2> monotonicity\n",
    "# train_x_smooth = train_xy.drop(columns=['FLAG']).rolling(window = 5, min_periods=1, center = False).mean()\n",
    "\n",
    "# 局部加权线性回归\n",
    "# def lwlr(x, X, Y, k):\n",
    "#     ''' 局部加权线性回归，给定一个点，获取相应权重矩阵并返回回归系数\n",
    "#     '''\n",
    "#     m = X.shape[0]\n",
    "#     print(m)\n",
    "#     # 创建针对x的权重矩阵\n",
    "#     W = np.matrix(np.zeros((m, m)))\n",
    "#     for i in range(m):\n",
    "#         xi = np.array(X[i][0])\n",
    "#         x = np.array(x)\n",
    "#         W[i, i] = np.exp((np.linalg.norm(x - xi))/(-2*k**2))\n",
    "#     # 获取此点相应的回归系数\n",
    "#     xWx = X.T*W*X\n",
    "#     if np.linalg.det(xWx) == 0:\n",
    "#         print('xWx is a singular matrix')\n",
    "#         return\n",
    "#     w = xWx.I*X.T*W*Y\n",
    "#     return w\n",
    "\n",
    "# lwlr(train_x_smooth.iloc[0,0], np.arange(len(train_x_smooth)), train_x_smooth.iloc[:,0].values.reshape(-1,1), 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.根据metric来排序特征，然后选择特征\n",
    "feature_rank = fisher_rank\n",
    "feature_rank = feature_rank\n",
    "selcted_features = list(feature_rank.index[:int(0.4*len(feature_rank))])\n",
    "train_x_baseline_sel = train_x_baseline[selcted_features]\n",
    "train_x_degraded_sel = train_x_degraded[selcted_features]\n",
    "train_x_sel = train_x[selcted_features]\n",
    "\n",
    "\n",
    "# 5.数据标准化\n",
    "# <1>定义baseline数据标准化函数\n",
    "def standard_scale(x):\n",
    "    if x.shape[0]==0:\n",
    "        return x,0,0\n",
    "    idx = x.index\n",
    "    m = x.mean()\n",
    "    std = x.std()\n",
    "    scaler = StandardScaler()   \n",
    "    x_arr = scaler.fit_transform(x)\n",
    "    return pd.DataFrame(x_arr, index = idx, columns =x.columns),m,std\n",
    "\n",
    "# <2>使用健康数据的m_b和std_b，定义对所有测试的数据做归一化标准化的函数\n",
    "def standard_scale_new(data,m_b,std_b):\n",
    "    cols = std_b[std_b==0].index\n",
    "    data_s = (data-m_b)/std_b\n",
    "    data_s[cols] = 0\n",
    "    return data_s\n",
    "\n",
    "train_x_baseline_stand,m_b,std_b = standard_scale(train_x_baseline_sel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_x_baseline_stand(DataFrame): 标准化的健康的特征数据   \n",
    "selcted_features(list):筛选出来的特征   \n",
    "train_x(DataFrame): 所有特征数据\n",
    "train_y(DataFrame): 所有的标签(FLAG)\n",
    "train_UNIQUENO(DataFrame):UNIQUENO  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.健康模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca and T2\n",
    "import joblib\n",
    "import os\n",
    "from sklearn.decomposition import PCA\n",
    "def dimension_reduction(x,whiten=True):\n",
    "    pca = PCA(n_components=0.95,whiten=whiten).fit(x)\n",
    "    return pca\n",
    "\n",
    "def cal_T2(data,pca):\n",
    "    T2=[]\n",
    "    projected_data = pca.transform(data)\n",
    "    eigenvalue_matrix = np.mat(np.diag(pca.singular_values_ ))\n",
    "    for x in projected_data:\n",
    "        tmp = np.mat(x)*np.linalg.inv(eigenvalue_matrix)*np.mat(x).T\n",
    "        T2.append(tmp[0,0])\n",
    "    return T2\n",
    "      \n",
    "# 使用归一化的健康数据\n",
    "pca = dimension_reduction(train_x_baseline_stand.values,whiten=False)\n",
    "if not os.path.exists('model'):\n",
    "    os.mkdir('./model')\n",
    "# 保存pca模型\n",
    "joblib.dump(pca,'./model/pca_%s_%s.pkl'%(start,end))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "健康模型pca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.概览"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ax.UNIQUENO.value_counts()[80:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 给定UNIQUENO，计算time-T2\n",
    "'''\n",
    "201706130830038670\n",
    "201707201730009538\n",
    "201801261730005948\n",
    "201705272357138269    \n",
    "'''\n",
    "\n",
    "'''\n",
    "全为健康的样本：\n",
    "201706130830038669\n",
    "201601250830021604\n",
    "201612151430019861\n",
    "201702251130053444\n",
    "'''\n",
    "UNIQUENO = 201707201730009538                                 \n",
    "train_unino = train_x_sel[train_UNIQUENO.UNIQUENO==UNIQUENO]\n",
    "train_unino_stand = standard_scale_new(train_unino,m_b,std_b)\n",
    "\n",
    "T2 = cal_T2(train_unino_stand,pca)\n",
    "T2 = pd.DataFrame(data=T2,columns=['T2'], index=train_unino.index)\n",
    "# T2_normal = T2/T2.max() # 归一化\n",
    "# T2_normal.plot()\n",
    "T2.plot()\n",
    "(T2.ewm(alpha=0.4).mean()).plot()\n",
    "train_ay[train_ay.UNIQUENO==UNIQUENO].drop(columns=['UNIQUENO']).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_degraded_stand = standard_scale_new(train_x_degraded_sel,m_b,std_b)\n",
    "T2_degraded = cal_T2(train_degraded_stand,pca)\n",
    "T2_degraded = pd.DataFrame(data=T2_degraded,columns=['T2_degraded'], index=train_degraded_stand.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.指定时间间隔，UNIQUENO，返回 可以直接计算数据（已做过相同的特征处理）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime as dt\n",
    "from datetime import timedelta\n",
    "\n",
    "\n",
    "def gen_interval(data,y,m_b,std_b,UNIQUENO,selcted_features,start='2017-03-01',end='2018-10-12'):\n",
    "\n",
    "    # 1.选数据\n",
    "    # <1> 选设备\n",
    "    data_unino = data[data.UNIQUENO==UNIQUENO].drop(columns=['UNIQUENO'])\n",
    "    y_unino = y[y.UNIQUENO==UNIQUENO].drop(columns=['UNIQUENO'])\n",
    "\n",
    "    # <2> 选时间片段\n",
    "    data_date = data_unino[start:end]\n",
    "    y_date = y_unino[start:end]\n",
    "    data_date.sort_index(inplace=True)\n",
    "    y_date.sort_index(inplace=True)\n",
    "    # <3> 选特征\n",
    "    data_sel = data_date[selcted_features]\n",
    "    \n",
    "    # 3.相同的特征处理\n",
    "    # <1> fillna\n",
    "    data_sel.fillna(0,inplace=True)\n",
    "    # <2>标准化\n",
    "    data_stand = standard_scale_new(data_sel,m_b,std_b)\n",
    "    return data_stand,y_date\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_stand,y_date = gen_interval(his_x,his_y,m_b,std_b,UNIQUENO,selcted_features,start='2017-03-01',end='2018-10-12')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.健康分排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cal_all_T2(x,y,m_b,std_b,selcted_features,start='2017-03-01',end='2018-10-12'):\n",
    "#     unino = data.UNIQUENO.value_counts().index[:100]\n",
    "#     res = dict()\n",
    "#     for UNIQUENO in unino:\n",
    "#         # 1.提取符合条件的数据\n",
    "#         data = gen_interval(x, y, m_b, std_b, UNIQUENO, selcted_features, start, end)\n",
    "#         # 2.计算T2值\n",
    "#         if data.empty:\n",
    "#             print('%s至%s,id为%d的设备无数据！'%(start,end,UNIQUENO))\n",
    "#             return None\n",
    "#         T2 = cal_T2(data_sel,pca)\n",
    "#         T2 = pd.DataFrame(data=T2,columns=['T2'], index=data.index)\n",
    "#         T2_ewm = T2.ewm(alpha=0.4).mean()\n",
    "#         # 输出T2_ewm(DataFrame)\n",
    "#     return T2_ewm\n",
    "\n",
    "def cal_all_T2(x,y,m_b,std_b,selcted_features,start='2017-03-01',end='2018-10-12'):\n",
    "    unino = y.UNIQUENO.value_counts().index[:100]\n",
    "    res = dict()\n",
    "    for UNIQUENO in unino:\n",
    "        # 1.提取符合条件的数据\n",
    "        data,_ = gen_interval(x, y, m_b, std_b, UNIQUENO, selcted_features, start, end)\n",
    "        # 2.计算T2值\n",
    "        if data.empty:\n",
    "            print('%s至%s,id为%d的设备无数据！'%(start,end,UNIQUENO))\n",
    "            continue\n",
    "        T2 = cal_T2(data,pca)\n",
    "        T2 = pd.DataFrame(data=T2,columns=['T2'], index=data.index)\n",
    "        T2_ewm = T2.ewm(alpha=0.4).mean()\n",
    "        T2_ewm_mean = T2_ewm['T2'].mean()\n",
    "        res[UNIQUENO] = T2_ewm_mean\n",
    "        # 输出T2_ewm(DataFrame)\n",
    "    score_rank = pd.Series(res).rank(method='dense',ascending=True).sort_values() # T2值大，排名靠后\n",
    "    return score_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 8s, sys: 6min 6s, total: 7min 14s\n",
      "Wall time: 36.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 计算指定天的分数\n",
    "score_rank = cal_all_T2(his_x,his_y,m_b,std_b,selcted_features,start='2017-03-01',end='2018-10-12')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.画指定时间间隔，UNIQUENO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(his_x,his_y,m_b,std_b,UNIQUENO,selcted_features,start='2017-03-01',end='2018-10-12'):\n",
    "    data_stand,y_date = gen_interval(his_x,his_y,m_b,std_b,UNIQUENO,selcted_features,start='2017-03-01',end='2018-10-12')\n",
    "    T2 = cal_T2(data,pca)\n",
    "    T2 = pd.DataFrame(data=T2,columns=['T2'], index=data.index)\n",
    "    T2_ewm = T2.ewm(alpha=0.4).mean()\n",
    "    T2_ewm.plot()\n",
    "    y_date.plot()\n",
    "    return T2_ewm,y_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'his_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-ec9761142768>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mT2_ewm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplot_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhis_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhis_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm_b\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstd_b\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mUNIQUENO\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mselcted_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'2017-03-01'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'2018-10-12'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'his_x' is not defined"
     ]
    }
   ],
   "source": [
    "T2_ewm,y_date = plot_data(his_x,his_y,m_b,std_b,UNIQUENO,selcted_features,start='2017-03-01',end='2018-10-12')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.计算每一维的贡献度  \n",
    "需要归一化后的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_sep_T2(data,pca):\n",
    "    '''\n",
    "    data(DataFrame):m个样本，n个维度\n",
    "    '''\n",
    "    # 计算总得分\n",
    "#     T2 = cal_T2(data,pca)\n",
    "    # 计算每个维度的得分\n",
    "    T2_cols = []\n",
    "    cols = list(data.columns)\n",
    "    for i in range(len(cols)):\n",
    "        tmp = np.zeros(data.shape)\n",
    "        tmp[:,i] = data.iloc[:,i].values\n",
    "        T2_col = cal_T2(tmp,pca)\n",
    "        T2_cols.append(T2_col)\n",
    "        \n",
    "#     T2 =np.array(T2).reshape((-1,1))\n",
    "    T2_cols = np.array(T2_cols).T\n",
    "#     T2_all = np.concatenate((T2,T2_cols),axis=1)\n",
    "#     return pd.DataFrame(data=T2_all, columns=['T2']+cols, index = data.index)\n",
    "    return pd.DataFrame(data=T2_cols,columns=cols,index=data.index)\n",
    "\n",
    "def cal_contrib(data,pca):\n",
    "    result = cal_sep_T2(data,pca)\n",
    "    res_mean = result.mean(axis=0)\n",
    "    res_sum = res_mean.sum()\n",
    "    contrib = res_mean/res_sum\n",
    "    contrib = contrib.sort_values(ascending=False)\n",
    "    return contrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.049999999999999996"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contrib.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for test\n",
    "\n",
    "# x = np.arange(20).reshape(-1,20)\n",
    "# cal_T2(x,pca)\n",
    "\n",
    "\n",
    "\n",
    "# y = np.diag(np.arange(20))\n",
    "# sum(cal_T2(y,pca))\n",
    "\n",
    "# x_t = pca.transform(x)\n",
    "\n",
    "# a = pca.components_\n",
    "\n",
    "# x.shape\n",
    "\n",
    "# x_t\n",
    "\n",
    "# cal_T2(x,pca)\n",
    "\n",
    "# y.shape\n",
    "\n",
    "# y_t = pca.transform(y)\n",
    "\n",
    "# y_t.sum(axis=0)\n",
    "\n",
    "# sum(cal_T2(y,pca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
