{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "#import lightgbm as lgb\n",
    "import warnings\n",
    "import gc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib as  mpl\n",
    "from matplotlib  import pyplot as plt\n",
    "mpl.rcParams[u'font.sans-serif'] = ['simhei']\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "from datetime import timedelta\n",
    "from datetime import datetime\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('C:\\\\Users\\\\linxiong.ruan\\\\Desktop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 33.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dataset = pd.read_csv('dataset.csv', index_col=0)\n",
    "dbd_faultcode = pd.read_csv('dbd_faultcode.csv', encoding='GBK' )\n",
    "train_data = dataset.merge(dbd_faultcode,how = 'left',on = [\"SPN\",\"FMI\"])\n",
    "up_data = train_data\n",
    "up_data.COLLECTTIME = pd.to_datetime(up_data.COLLECTTIME)\n",
    "up_data.sort_values(by='COLLECTTIME', inplace=True)\n",
    "# 删除明显异常的行\n",
    "drop_rows = [0, 1, 2, 3]\n",
    "drop_rows.extend([x for x in range(1875076, 1875088)])\n",
    "up_data.drop(drop_rows, axis=0, inplace=True)\n",
    "# 默认填充为0\n",
    "up_data[\"FLAG\"] = 0\n",
    "# 筛选出故障编码不为空的UNIQUENO(一个UNIQUENO可假设为一台机器)\n",
    "prob_uniqs = up_data[up_data.CODE.notnull()].UNIQUENO.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "Wall time: 33.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 出现故障的时间段进行标记\n",
    "'''\n",
    "minutes = 300\n",
    "'''\n",
    "# 设定优先级，对于少数种类的故障，优先标记\n",
    "code_prev = {\n",
    "    1206: 0,\n",
    "    1141: 1,\n",
    "    1182: 2,\n",
    "    1168: -1,\n",
    "    1239: -1,\n",
    "    1168: -1,\n",
    "    1211: -1,\n",
    "    1216: -1,\n",
    "    1209: -1,\n",
    "    1145: -1,\n",
    "    1341: -1,\n",
    "    1246: -1,\n",
    "    1215: -1,\n",
    "    1122: -1\n",
    "}\n",
    "\n",
    "delta = timedelta(minutes = 300)\n",
    "left_delta = delta\n",
    "right_delta = delta\n",
    "# 从有故障的设备列表中取出一台设备\n",
    "for dev_id in prob_uniqs:\n",
    "    # 取出这台设备的全部数据\n",
    "    cdf = up_data[up_data.UNIQUENO == dev_id].copy()\n",
    "    cdf['index'] = cdf.index\n",
    "    cdf.reset_index(inplace=True)\n",
    "    # 取出这台设备故障码不为空的数据\n",
    "    notna_cdf = cdf[cdf.CODE.notna()]\n",
    "#     print(datetime.now(), dev_id, cdf.shape[0], notna_cdf.shape[0])\n",
    "    cdf_len = cdf.shape[0]\n",
    "    # 在这台设备数据中遍历不为空的位置\n",
    "    for i in notna_cdf.index:\n",
    "        dt = cdf.at[i, 'COLLECTTIME']\n",
    "        code = cdf.at[i, 'CODE']\n",
    "        # 在前后时间间隔内打标签\n",
    "        for y in range(i, -1, -1):\n",
    "            y_code = up_data.at[cdf.at[y, 'index'], 'FLAG']\n",
    "            if y_code > 0 and code_prev[y_code] >= code_prev[code]:\n",
    "                break\n",
    "            elif cdf.at[y, 'COLLECTTIME'] >= dt - left_delta:\n",
    "                up_data.at[cdf.at[y, 'index'], 'FLAG'] = code\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        for y in range(i + 1, cdf_len, 1):\n",
    "            y_code = up_data.at[cdf.at[y, 'index'], 'FLAG']\n",
    "            if y_code > 0 and code_prev[y_code] >= code_prev[code]:\n",
    "                break\n",
    "            elif cdf.at[y, 'COLLECTTIME'] <= dt + right_delta:\n",
    "                up_data.at[cdf.at[y, 'index'], 'FLAG'] = code\n",
    "            else:\n",
    "                break\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#columns_filter,util_cols由人工提供\n",
    "columns_filter = ['CD_VP_UNIQUENO', 'AREA', 'ROAD', 'LONGITUDE', 'LATITUDE', 'SPEED',\n",
    "       'DIRECTION', 'ALTITUDE', 'ACCSTATE', 'POWERDOWNSTATE', 'LOCATIONSTATE',\n",
    "       'WORKHOURS', 'ACCRUNTIMES', 'ACCWORKTIMES', 'PRESSURE',\n",
    "       'WATERTEMPERATURE', 'OILLOCATION', 'OILTEMPERATURE', 'OILPRESSURE',\n",
    "       'ROUNDSPEED', 'ACCEXCCOUNT', 'GSMSIGNAL', 'WORKDETAILID',\n",
    "       'VEHICLESTATUS', 'TERMINALSTATUS', 'SATELLITE', 'TERMINALEL_OUTSIDE',\n",
    "       'TERMINALEL_INSIDE', 'INSIDE_TEMPERATURE', 'INSIDE_HUMIDITY',\n",
    "       'MILENUMBER', 'OILVALUE1', 'OILVALUE2', 'MIXSTATE', 'QUSHOILTIMES',\n",
    "       'ENVTEMPERATURE', 'PULSESIGNS', 'ENVHUMIDITY', 'OILPERCENT1',\n",
    "       'ELCANDVOL', 'WIRELESSTEMP1', 'WIRELESSTEMP2', 'WIRELESSTEMP3',\n",
    "       'WIRELESSTEMP4', 'SIMNO', 'OPTOILLEVEL', 'ENGINELOADSTATE', 'CMDTYPE',\n",
    "       'ISANALYSED', 'VERSIONNUM', 'LOCK_INSTRUMENT', 'ALARM_0010',\n",
    "       'ALARM_0003', 'ALARM_0008', 'ALARM_0005', 'ALARM_0006', 'ALARM_0007',\n",
    "       'ALARM_0009', 'LOWVOLTAGESTATUS', 'ALARM_0002', 'ALARM_0004',\n",
    "       'ALARM_0001', 'THROTTLECURRENT', 'CURRENTSPEEDLOADPERCENTAGE',\n",
    "       'ENGINETORQUEPERCENT', 'ROTATIONALSPEED', 'ENGINERUNTIMES',\n",
    "       'COOLANTTEMPERATURE', 'ENGINEOILTEMPERATURE', 'INTAKETEMPERATURE',\n",
    "       'TEMPERATURE', 'LUBRICATINGOILPRESSURE', 'COOLANTLEVEL',\n",
    "       'INTAKEMANIFOLDTEMPERATURE', 'FUELUSETOTAL', 'OILCONSUMPTIONRATE',\n",
    "       'CURRENTFAULTCOUNT1', 'CURRENTFAULTCOUNT2', 'CURRENTFAULTCOUNT3',\n",
    "       'CURRENTFAULTCOUNT4', 'CURRENTFAULTCOUNT5', 'CURRENTFAULTCOUNT6','FLAG','UNIQUENO','COLLECTTIME']\n",
    "util_cols = ['COLLECTTIME','FLAG','UNIQUENO']\n",
    "\n",
    "# 筛选出这四类故障的数据\n",
    "x_train = up_data[up_data.FLAG.isin({0,1206,1141,1182})]\n",
    "x_data = x_train[columns_filter]\n",
    "y_train = x_data['FLAG']\n",
    "y_train.replace(1206,1,inplace=True)\n",
    "y_train.replace(1141,2,inplace=True)\n",
    "y_train.replace(1182,3,inplace=True)\n",
    "x_data['FLAG'] = y_train.values \n",
    "x_data.index = pd.to_datetime(x_data['COLLECTTIME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_cols = ['UNIQUENO','CD_VP_UNIQUENO', 'AREA', 'ROAD', 'LONGITUDE', 'LATITUDE', 'SPEED',\n",
    "       'DIRECTION', 'ALTITUDE', 'ACCSTATE', 'POWERDOWNSTATE', 'LOCATIONSTATE',\n",
    "       'WORKHOURS', 'ACCRUNTIMES', 'ACCWORKTIMES', 'PRESSURE',\n",
    "       'WATERTEMPERATURE', 'OILLOCATION', 'OILTEMPERATURE', 'OILPRESSURE',\n",
    "       'ROUNDSPEED', 'ACCEXCCOUNT', 'GSMSIGNAL', 'WORKDETAILID',\n",
    "       'VEHICLESTATUS', 'TERMINALSTATUS', 'SATELLITE', 'TERMINALEL_OUTSIDE',\n",
    "       'TERMINALEL_INSIDE', 'INSIDE_TEMPERATURE', 'INSIDE_HUMIDITY',\n",
    "       'MILENUMBER', 'OILVALUE1', 'OILVALUE2', 'MIXSTATE', 'QUSHOILTIMES',\n",
    "       'ENVTEMPERATURE', 'PULSESIGNS', 'ENVHUMIDITY', 'OILPERCENT1',\n",
    "       'ELCANDVOL', 'WIRELESSTEMP1', 'WIRELESSTEMP2', 'WIRELESSTEMP3',\n",
    "       'WIRELESSTEMP4', 'SIMNO', 'OPTOILLEVEL', 'ENGINELOADSTATE', 'CMDTYPE',\n",
    "       'ISANALYSED', 'VERSIONNUM', 'LOCK_INSTRUMENT', 'ALARM_0010',\n",
    "       'ALARM_0003', 'ALARM_0008', 'ALARM_0005', 'ALARM_0006', 'ALARM_0007',\n",
    "       'ALARM_0009', 'LOWVOLTAGESTATUS', 'ALARM_0002', 'ALARM_0004',\n",
    "       'ALARM_0001', 'THROTTLECURRENT', 'CURRENTSPEEDLOADPERCENTAGE',\n",
    "       'ENGINETORQUEPERCENT', 'ROTATIONALSPEED', 'ENGINERUNTIMES',\n",
    "       'COOLANTTEMPERATURE', 'ENGINEOILTEMPERATURE', 'INTAKETEMPERATURE',\n",
    "       'TEMPERATURE', 'LUBRICATINGOILPRESSURE', 'COOLANTLEVEL',\n",
    "       'INTAKEMANIFOLDTEMPERATURE', 'FUELUSETOTAL', 'OILCONSUMPTIONRATE',\n",
    "       'CURRENTFAULTCOUNT1', 'CURRENTFAULTCOUNT2', 'CURRENTFAULTCOUNT3',\n",
    "       'CURRENTFAULTCOUNT4', 'CURRENTFAULTCOUNT5', 'CURRENTFAULTCOUNT6']\n",
    "train_y_col = ['UNIQUENO','FLAG']\n",
    "train_ax = x_data[train_x_cols]\n",
    "train_ay = x_data[train_y_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"删方差为0的列\"\"\"\n",
    "def drop_wubianhua(data):\n",
    "    wubianhualie=data.columns[np.std(data,axis=0)==0]\n",
    "    return data.drop(wubianhualie,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "计算fisher得分,筛选得分高于平均值的变量 。该步骤需要提前标准化\n",
    "\"\"\"\n",
    "def fisher(data,y):  ###data是包含健康，故障数据,不包含y，y是健康与否\n",
    "    def fisher(x,y):\n",
    "        guzhang=x[y.FLAG==1]\n",
    "        jiankang=x[y.FLAG==0]\n",
    "        return np.square(np.mean(guzhang)-np.mean(jiankang))/np.sqrt((np.var(guzhang)+np.var(jiankang)))\n",
    "    f=np.zeros(data.shape[1])\n",
    "    tem=0\n",
    "    for i in range(data.shape[1]):\n",
    "        f[tem]=fisher(data.iloc[:,i:(i+1)],y)\n",
    "        tem=tem+1\n",
    "    return f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "相关系数大于0.9的取fisher得分高的\n",
    "\"\"\"\n",
    "cor_value=0.9\n",
    "def cor_fisher(data,y):\n",
    "    def fisher(x,y):\n",
    "        guzhang=x[y.FLAG==1]\n",
    "        jiankang=x[y.FLAG==0]\n",
    "        return np.square(np.mean(guzhang)-np.mean(jiankang))/np.sqrt((np.var(guzhang)+np.var(jiankang)))\n",
    "\n",
    "    cor=data.corr()\n",
    "\n",
    "    cor=np.triu(cor,1)\n",
    "\n",
    "    loc=np.where(cor>cor_value)\n",
    "\n",
    "    loc=pd.DataFrame({\"n\":loc[0],\"p\":loc[1]})\n",
    "\n",
    "    tem=[]\n",
    "    for i in range(loc.shape[0]):\n",
    "        row=np.array(loc.iloc[i:i+1,:])\n",
    "        row=data.columns[row[0]]\n",
    "        d1=data[row[0]]\n",
    "        d2=data[row[1]]\n",
    "        f1=fisher(d1,y)\n",
    "        f2=fisher(d2,y)\n",
    "        tem.append(row[(f1>f2)*1])\n",
    "\n",
    "    return data.drop(tem,axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def CDF_out(data,newdata,pvalue=0.95):   ####该处data是一个peer的所有数据\n",
    "    newdata=np.array(newdata)\n",
    "    n=newdata.shape[0]\n",
    "    p=newdata.shape[1]\n",
    "    re=np.zeros((n,p))\n",
    "    def CDF(data):\n",
    "            return np.percentile(data,1-pvalue)\n",
    "            \n",
    "    for j in range(p):\n",
    "        inter=CDF(data.iloc[:,j])\n",
    "        for i in range(n):\n",
    "            re[i,j]=((newdata[i,j]>inter))\n",
    "    return re.sum(axis=1)\n",
    "\n",
    "#print(count_all)\n",
    "def score(score): \n",
    "    k=10/(np.min(score)-np.median(score))\n",
    "    return 90+k*(score-np.median(score))\n",
    "\n",
    "def pinghua(score,alpha=0.5):\n",
    "    for i in range(1,len(score)):\n",
    "            score[i]=(1-alpha)*score[i-1]+alpha*score[i]\n",
    "    return score\n",
    "\n",
    "def standard_scale(x):\n",
    "    return (np.mean(x,axis=0),np.std(x,axis=0))\n",
    "\n",
    "def s_type(data):\n",
    "    sk=data.skew(axis=0)\n",
    "    if(sum(sk<-2)>0):\n",
    "        data[data.columns[sk<-2]]=-data[data.columns[sk<-2]]\n",
    "    if(sum((sk<=2)*(sk>=-2))>0):\n",
    "        data[data.columns[(sk<=2)*(sk>=-2)]]=abs(data[data.columns[(sk<=2)*(sk>=-2)]])\n",
    "    return data\n",
    "\n",
    "class score_cdf(object):\n",
    "    def __init__(self,train_ax,train_ay):\n",
    "        self.train_ax=train_ax\n",
    "        self.train_ay=train_ay\n",
    "    def datahandling(self,pr=False):\n",
    "        self.ID=self.train_ax.UNIQUENO\n",
    "        self.train_ax=self.train_ax.drop([\"UNIQUENO\"],axis=1)\n",
    "        self.train_ax.fillna(0,inplace=True)\n",
    "        self.train_ax=drop_wubianhua(self.train_ax)\n",
    "        (self.mean,self.std) = standard_scale(self.train_ax)\n",
    "        self.train_ax=(self.train_ax-self.mean)/self.std\n",
    "        self.sk=self.train_ax.skew(axis=0)\n",
    "        if(sum(self.sk<-2)>0):\n",
    "            self.train_ax[self.train_ax.columns[self.sk<-2]]=-self.train_ax[self.train_ax.columns[self.sk<-2]]\n",
    "        if(sum((self.sk<=2)*(self.sk>=-2))>0):\n",
    "            self.train_ax[self.train_ax.columns[(self.sk<=2)*(self.sk>=-2)]]=abs(self.train_ax[self.train_ax.columns[(self.sk<=2)*(self.sk>=-2)]])\n",
    "        f=fisher(self.train_ax,self.train_ay)\n",
    "        self.train_ax=self.train_ax[self.train_ax.columns[f>np.mean(f)]]\n",
    "        self.train_ax=cor_fisher(self.train_ax,self.train_ay)\n",
    "        (self.mean,self.std,self.sk)=(self.mean[self.train_ax.columns],self.std[self.train_ax.columns],self.sk[self.train_ax.columns])\n",
    "        if pr:\n",
    "            print(\"选出的变量：\",self.train_ax.columns)\n",
    "    def Inter(self,pvalue=0.95):\n",
    "        def CDF(data,pvalue):\n",
    "            return np.percentile(data,1-pvalue)\n",
    "        Int=np.zeros(self.train_ax.shape[1])\n",
    "        k=0\n",
    "        for i in self.train_ax.columns:\n",
    "            Int[k]=CDF(self.train_ax[i],pvalue)\n",
    "            k=k+1\n",
    "        self.Int=Int\n",
    "    def newdatahand(self,newdata):\n",
    "        newdata=pd.DataFrame(newdata).T\n",
    "        newd=newdata[self.train_ax.columns]\n",
    "        #print(newd)\n",
    "        newd.fillna(0,inplace=True)\n",
    "        #print(newd)\n",
    "        self.newdata=pd.DataFrame(np.array(newd-self.mean)/np.array(self.std),columns=newd.columns)\n",
    "        #print(newd-self.mean)\n",
    "        if(sum(self.sk<-2)>0):\n",
    "            self.newdata[self.newdata.columns[self.sk<-2]]=-self.newdata[self.newdata.columns[self.sk<-2]]\n",
    "        if(sum((self.sk<=2)*(self.sk>=-2))>0):\n",
    "            self.newdata[self.newdata.columns[(self.sk<=2)*(self.sk>=-2)]]=abs(self.newdata[self.newdata.columns[(self.sk<=2)*(self.sk>=-2)]])\n",
    "        #print(self.newdata)\n",
    "    '''\n",
    "    def lishidefen(self):\n",
    "        re=np.zeros(self.train_ax.shape[0])\n",
    "        for i in range(self.train_ax.shape[0]):\n",
    "            re[i]=sum(self.train_ax.iloc[i,:]>self.Int)\n",
    "        self.min=np.min(re)\n",
    "        self.med=np.median(re)\n",
    "    '''\n",
    "    def sc(self,health=True):\n",
    "        if health:\n",
    "            self.train_ax = self.train_ax[self.train_ay.FLAG==0]\n",
    "        count_all=sum(np.array(self.newdata)[0]>self.Int)\n",
    "        #k=10/(self.min-self.med)\n",
    "        #score=90+k*(count_all-self.med)\n",
    "        k=50/(0-7)\n",
    "        score=100+k*(count_all)\n",
    "        return score\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.根据设备的UNIQUENO取数据，做数据处理\n",
    "'''\n",
    "201706130830038670\n",
    "201707201730009538\n",
    "201801261730005948\n",
    "'''\n",
    "'''\n",
    "UNIQUENO = 201706130830038670\n",
    "#train_ax_health = train_ax[train_ay.FLAG==0]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "选出的变量： Index(['LATITUDE', 'LOCATIONSTATE', 'ACCRUNTIMES', 'GSMSIGNAL', 'SATELLITE',\n",
      "       'CMDTYPE', 'CURRENTFAULTCOUNT1'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "y=score_cdf(train_ax,train_ay)\n",
    "y.datahandling(pr=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.Inter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78.57142857142857"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.newdatahand(train_ax.iloc[1,:])\n",
    "y.sc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def t(d):\n",
    "    timeStamp=np.zeros(d.shape[0])\n",
    "    for i in range(d.shape[0]):\n",
    "        timeArray = time.strptime(str(d[i]), \"%Y-%m-%d %H:%M:%S\")\n",
    "        timeStamp[i] = (int(time.mktime(timeArray))//86400)\n",
    "    return timeStamp\n",
    "ID_all=np.unique(train_ax.UNIQUENO)\n",
    "day=t(train_ax.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"最近10天内所有数据\"\"\"\n",
    "nearday=max(day)\n",
    "passbyday=max(day)-10\n",
    "\n",
    "newdata=train_ax[(day<nearday)*(day>passbyday)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"最近10天的所有得分\n",
    "re=pd.DataFrame(\n",
    "for i in range(newdata.shape[0]):\n",
    "    y.newdatahand(newdata.iloc[i,])\n",
    "    y.sc()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCORE=pd.DataFrame(index=np.unique(day[(day<nearday)*(day>passbyday)]),columns=np.unique(train_ax.UNIQUENO))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Float64Index([17642.0, 17643.0, 17644.0, 17645.0, 17646.0, 17647.0, 17648.0,\n",
       "              17649.0, 17650.0],\n",
       "             dtype='float64')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SCORE.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=17650.0\n",
    "j=201405151234131891\n",
    "train_ax[\"xuanze\"]=((day==i)*(train_ax.UNIQUENO==j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_oneday_oneid=pd.DataFrame(train_ax[train_ax.xuanze==True].drop(['xuanze'],axis=1),columns=train_ax.columns)\n",
    "        #data_oneday_oneid=pd.DataFrame(train_ax[(day==i)*(train_ax.UNIQUENO==j),:],columns=train_ax.columns)\n",
    "oneday_oneid_score=np.zeros(data_oneday_oneid.shape[0])\n",
    "for k in range(data_oneday_oneid.shape[0]):\n",
    "            y.newdatahand(data_oneday_oneid.iloc[k,:])\n",
    "            oneday_oneid_score[k]=y.sc()\n",
    "SCORE.loc[i,j]=np.max(oneday_oneid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in SCORE.index:\n",
    "    for j in SCORE.columns:\n",
    "        train_ax[\"xuanze\"]=((day==i)*(train_ax.UNIQUENO==j))\n",
    "        data_oneday_oneid=pd.DataFrame(train_ax[train_ax.xuanze==True].drop(['xuanze'],axis=1),columns=train_ax.columns)\n",
    "        #data_oneday_oneid=pd.DataFrame(train_ax[(day==i)*(train_ax.UNIQUENO==j),:],columns=train_ax.columns)\n",
    "        oneday_oneid_score=np.zeros(data_oneday_oneid.shape[0])\n",
    "        for k in range(data_oneday_oneid.shape[0]):\n",
    "            y.newdatahand(data_oneday_oneid.iloc[k,:])\n",
    "            oneday_oneid_score[k]=y.sc()\n",
    "        SCORE.loc[i,j]=np.max(oneday_oneid_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
